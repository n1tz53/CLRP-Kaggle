{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hundred-spokesman",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-20T06:27:40.436536Z",
     "iopub.status.busy": "2021-07-20T06:27:40.435783Z",
     "iopub.status.idle": "2021-07-20T06:27:47.404637Z",
     "shell.execute_reply": "2021-07-20T06:27:47.403573Z",
     "shell.execute_reply.started": "2021-07-20T06:14:49.829542Z"
    },
    "papermill": {
     "duration": 6.993171,
     "end_time": "2021-07-20T06:27:47.404801",
     "exception": false,
     "start_time": "2021-07-20T06:27:40.411630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "from math import ceil, log, sqrt\n",
    "from collections import deque, defaultdict, Counter\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader,\\\n",
    "                             WeightedRandomSampler\n",
    "import transformers\n",
    "from transformers import RobertaTokenizer,\\\n",
    "                         RobertaModel,\\\n",
    "                         AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "computational-valuable",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T06:27:47.426015Z",
     "iopub.status.busy": "2021-07-20T06:27:47.425361Z",
     "iopub.status.idle": "2021-07-20T06:27:47.431093Z",
     "shell.execute_reply": "2021-07-20T06:27:47.430699Z",
     "shell.execute_reply.started": "2021-07-20T06:14:49.853097Z"
    },
    "papermill": {
     "duration": 0.018075,
     "end_time": "2021-07-20T06:27:47.431237",
     "exception": false,
     "start_time": "2021-07-20T06:27:47.413162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "terminal-vulnerability",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T06:27:47.501071Z",
     "iopub.status.busy": "2021-07-20T06:27:47.500233Z",
     "iopub.status.idle": "2021-07-20T06:27:47.503272Z",
     "shell.execute_reply": "2021-07-20T06:27:47.502795Z",
     "shell.execute_reply.started": "2021-07-20T06:14:49.866024Z"
    },
    "papermill": {
     "duration": 0.063978,
     "end_time": "2021-07-20T06:27:47.503406",
     "exception": false,
     "start_time": "2021-07-20T06:27:47.439428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "magnetic-counter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T06:27:47.526108Z",
     "iopub.status.busy": "2021-07-20T06:27:47.525576Z",
     "iopub.status.idle": "2021-07-20T06:27:47.622269Z",
     "shell.execute_reply": "2021-07-20T06:27:47.621400Z",
     "shell.execute_reply.started": "2021-07-20T06:14:49.879148Z"
    },
    "papermill": {
     "duration": 0.11068,
     "end_time": "2021-07-20T06:27:47.622407",
     "exception": false,
     "start_time": "2021-07-20T06:27:47.511727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id url_legal license  \\\n",
       "0  c12129c31       NaN     NaN   \n",
       "1  85aa80a4c       NaN     NaN   \n",
       "2  b69ac6792       NaN     NaN   \n",
       "3  dd1000b26       NaN     NaN   \n",
       "4  37c1b32fb       NaN     NaN   \n",
       "\n",
       "                                             excerpt    target  standard_error  \n",
       "0  When the young people returned to the ballroom... -0.340259        0.464009  \n",
       "1  All through dinner time, Mrs. Fayre was somewh... -0.315372        0.480805  \n",
       "2  As Roger had predicted, the snow departed as q... -0.580118        0.476676  \n",
       "3  And outside before the palace a great garden w... -1.054013        0.450007  \n",
       "4  Once upon a time there were Three Bears who li...  0.247197        0.510845  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "df['excerpt'] = df['excerpt'].str.replace('\\n', ' ')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polar-evans",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T06:27:47.648625Z",
     "iopub.status.busy": "2021-07-20T06:27:47.647736Z",
     "iopub.status.idle": "2021-07-20T06:27:47.660934Z",
     "shell.execute_reply": "2021-07-20T06:27:47.660489Z",
     "shell.execute_reply.started": "2021-07-20T06:14:49.967939Z"
    },
    "papermill": {
     "duration": 0.029213,
     "end_time": "2021-07-20T06:27:47.661047",
     "exception": false,
     "start_time": "2021-07-20T06:27:47.631834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fold(df, num_splits, column):\n",
    "    \n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    num_bins = int(ceil(log(len(df), 2) + 1))\n",
    "    df['bin'] = pd.cut(df[column], num_bins, labels=False)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=num_splits)\n",
    "    df['fold'] = -1\n",
    "    \n",
    "    for fold, (_, idxs) in enumerate(skf.split(df, df['bin'].values)):\n",
    "        df.loc[idxs, 'fold'] = fold\n",
    "    # df.drop('bin', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "num_folds = 5\n",
    "df = create_fold(df, num_folds, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rocky-theory",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T06:27:47.691621Z",
     "iopub.status.busy": "2021-07-20T06:27:47.690815Z",
     "iopub.status.idle": "2021-07-20T06:27:51.593785Z",
     "shell.execute_reply": "2021-07-20T06:27:51.593341Z",
     "shell.execute_reply.started": "2021-07-20T06:14:49.991576Z"
    },
    "papermill": {
     "duration": 3.924005,
     "end_time": "2021-07-20T06:27:51.593907",
     "exception": false,
     "start_time": "2021-07-20T06:27:47.669902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b854711e5e743168ce764f5ce66fa72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b6f0902d154353957e96eb29366d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342644bc18e44735b51eb1a5f8e58cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "class CLRPDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, excerpts, targets):\n",
    "        \n",
    "        self.excerpts = excerpts\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        excerpt = self.excerpts[idx]\n",
    "        encode_excerpt = tokenizer.encode_plus(excerpt,\n",
    "                                               padding=False,\n",
    "                                               return_attention_mask=True)\n",
    "        \n",
    "        ids = torch.tensor(encode_excerpt['input_ids'], \n",
    "                           dtype=torch.long)\n",
    "        mask = torch.tensor(encode_excerpt['attention_mask'], \n",
    "                            dtype=torch.long)\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "        \n",
    "        return {'ids': ids, 'mask': mask, 'target': target}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpts)\n",
    "\n",
    "class CLRPCollate:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        \n",
    "        res = {'ids': [], 'mask': [], \n",
    "               'target': [], 'bin': []}\n",
    "        \n",
    "        max_len = 0\n",
    "        \n",
    "        for example in batch:\n",
    "            res['ids'].append(example['ids'].numpy())\n",
    "            res['mask'].append(example['mask'].numpy())\n",
    "            res['target'].append(example['target'])\n",
    "            max_len = max(max_len, len(res['ids'][-1]))\n",
    "        \n",
    "        for idx in range(len(batch)):\n",
    "            ones = np.ones(max_len - len(res['ids'][idx]))\n",
    "            res['ids'][idx] = np.concatenate([res['ids'][idx], ones])\n",
    "            ones = np.ones(max_len - len(res['mask'][idx]))\n",
    "            res['mask'][idx] = np.concatenate([res['mask'][idx], ones])\n",
    "            \n",
    "        res['ids'] = torch.tensor(res['ids'], dtype=torch.long)\n",
    "        res['mask'] = torch.tensor(res['mask'], dtype=torch.long)\n",
    "        res['target'] = torch.tensor(res['target'], dtype=torch.float)\n",
    "        \n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "standing-charity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T06:27:51.627751Z",
     "iopub.status.busy": "2021-07-20T06:27:51.627060Z",
     "iopub.status.idle": "2021-07-20T06:27:51.630422Z",
     "shell.execute_reply": "2021-07-20T06:27:51.629991Z",
     "shell.execute_reply.started": "2021-07-20T06:14:52.205177Z"
    },
    "papermill": {
     "duration": 0.026465,
     "end_time": "2021-07-20T06:27:51.630527",
     "exception": false,
     "start_time": "2021-07-20T06:27:51.604062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Averager:\n",
    "    \n",
    "    def __init__(self, maxlen=16):\n",
    "        self.values = deque(maxlen=maxlen)\n",
    "        self.total = 0.\n",
    "        self.count = 0\n",
    "        return\n",
    "    \n",
    "    def update(self, value):\n",
    "        self.values.append(value)\n",
    "        self.total += value\n",
    "        self.count += 1\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    def avg(self):\n",
    "        return np.mean(self.values)\n",
    "    \n",
    "    @property\n",
    "    def global_avg(self):\n",
    "        return self.total / self.count\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.avg:.3f} ({self.global_avg:.3f})'\n",
    "\n",
    "class Traininglog:\n",
    "    \n",
    "    def __init__(self, sep=' '):\n",
    "        self.metrics = defaultdict(Averager)\n",
    "        self.sep = sep\n",
    "        return\n",
    "    \n",
    "    def update(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            assert isinstance(value, (float, int))\n",
    "            self.metrics[key].update(value)\n",
    "        return\n",
    "    \n",
    "    def __str__(self):\n",
    "        loss_str = []\n",
    "        for key, value in self.metrics.items():\n",
    "            loss_str.append(f'{key}: {value}')\n",
    "        return self.sep.join(loss_str)\n",
    "    \n",
    "    def run_iterations(self, iterable, print_freq, header=''):\n",
    "        step = 0\n",
    "        start = time()\n",
    "        log_msg = self.sep.join([header, '[{0:02d}/{1}]', 'eta: {eta}',\n",
    "                                 '{metrics}','time: {time}', 'data: {data}'])\n",
    "        data_time = Averager()\n",
    "        iter_time = Averager()\n",
    "        end = time()\n",
    "        \n",
    "        for obj in iterable:\n",
    "            data_time.update(time() - end)\n",
    "            yield obj\n",
    "            iter_time.update(time() - end)\n",
    "            if (step + 1) % print_freq == 0 or step == len(iterable) - 1:\n",
    "                eta_secs = iter_time.global_avg * (len(iterable) - 1)\n",
    "                eta_str = f'{timedelta(seconds=int(eta_secs))}'\n",
    "                print(log_msg.format(step, len(iterable), eta=eta_str,\n",
    "                                     metrics=self, time=iter_time, \n",
    "                                     data=data_time))\n",
    "            end = time()\n",
    "            step += 1\n",
    "            \n",
    "        total_time = time() - start\n",
    "        total_time = f'{timedelta(seconds=int(total_time))}'\n",
    "        print(f'Total time: {total_time}')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reserved-madagascar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T06:27:51.657360Z",
     "iopub.status.busy": "2021-07-20T06:27:51.656686Z",
     "iopub.status.idle": "2021-07-20T06:27:51.658984Z",
     "shell.execute_reply": "2021-07-20T06:27:51.659450Z",
     "shell.execute_reply.started": "2021-07-20T06:14:52.224131Z"
    },
    "papermill": {
     "duration": 0.019539,
     "end_time": "2021-07-20T06:27:51.659592",
     "exception": false,
     "start_time": "2021-07-20T06:27:51.640053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_dim, hidden_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.W_qk = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.W_v = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, hidden_states):\n",
    "        alpha = self.W_v(torch.tanh(self.W_qk(hidden_states)))\n",
    "        score = torch.softmax(alpha, dim=1)\n",
    "        context = score * hidden_states\n",
    "        return torch.sum(context, dim=1)\n",
    "        \n",
    "class CLRPModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CLRPModel, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.attention_head = AttentionHead(768, 512)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.regressor = nn.Linear(768, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        hidden_states = self.roberta(input_ids, attention_mask).last_hidden_state\n",
    "        return self.regressor(self.dropout(self.attention_head(hidden_states)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "automatic-hearts",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T06:27:51.691806Z",
     "iopub.status.busy": "2021-07-20T06:27:51.686358Z",
     "iopub.status.idle": "2021-07-20T06:27:51.693973Z",
     "shell.execute_reply": "2021-07-20T06:27:51.694428Z",
     "shell.execute_reply.started": "2021-07-20T06:14:52.238780Z"
    },
    "papermill": {
     "duration": 0.025205,
     "end_time": "2021-07-20T06:27:51.694546",
     "exception": false,
     "start_time": "2021-07-20T06:27:51.669341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "\n",
    "def loss_func(output, target):\n",
    "    return torch.sqrt(nn.MSELoss()(output, target))\n",
    "\n",
    "\n",
    "def validation(val_dataloader, model):\n",
    "    \n",
    "    log = Traininglog()\n",
    "    header = 'Validation'\n",
    "    run_target = []\n",
    "    run_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for batch in log.run_iterations(val_dataloader, 50, header=header):\n",
    "\n",
    "            ids = batch['ids'].to(device, non_blocking=True)\n",
    "            mask = batch['mask'].to(device, non_blocking=True)\n",
    "            end = time()\n",
    "            output = model(ids, mask)\n",
    "            inference_time = time() - end\n",
    "            output = output.squeeze(-1)\n",
    "            run_pred.append(output.to('cpu'))\n",
    "            run_target.append(batch['target'])\n",
    "            log.update(inference_time=inference_time)\n",
    "            \n",
    "            del mask, ids\n",
    "            \n",
    "        run_target = np.concatenate(run_target)\n",
    "        run_pred = np.concatenate(run_pred)\n",
    "    return np.sqrt(mean_squared_error(run_target, run_pred))\n",
    "\n",
    "\n",
    "def train_eval_one_epoch(fold, epoch, train_dataloader, val_dataloader, \n",
    "                         eval_steps, min_loss, model, optimizer, lr_scheduler):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    log = Traininglog()\n",
    "    header = f'Epoch[{epoch}]'\n",
    "    \n",
    "    steps = 0\n",
    "    min_loss = min_loss\n",
    "    \n",
    "    for batch in log.run_iterations(train_dataloader, eval_steps, header=header):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ids = batch['ids'].to(device, non_blocking=True)\n",
    "        mask = batch['mask'].to(device, non_blocking=True)\n",
    "        target = batch['target'].to(device, non_blocking=True)\n",
    "        \n",
    "        output = model(ids, mask)\n",
    "        output = output.squeeze(-1)\n",
    "        \n",
    "        loss = loss_func(output, target)\n",
    "                \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        log.update(train_loss=loss.item())\n",
    "        del loss, output, target, mask, ids\n",
    "        \n",
    "        steps += 1\n",
    "        if (steps + 1) % eval_steps == 0 or steps == len(train_dataloader):\n",
    "            val_loss = validation(val_dataloader, model)\n",
    "            print(f'val_loss: {val_loss}')\n",
    "            if val_loss < min_loss:\n",
    "                print(f'min_loss decreased from {min_loss} to {val_loss}.')\n",
    "                print(f'saving model...')\n",
    "                torch.save(model.state_dict(), f'roberta-baseline-fold{fold}.pth')\n",
    "                min_loss = val_loss\n",
    "            \n",
    "    return min_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "developmental-fleet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T06:27:51.724117Z",
     "iopub.status.busy": "2021-07-20T06:27:51.723524Z",
     "iopub.status.idle": "2021-07-20T07:07:01.504771Z",
     "shell.execute_reply": "2021-07-20T07:07:01.504329Z"
    },
    "papermill": {
     "duration": 2349.80075,
     "end_time": "2021-07-20T07:07:01.504907",
     "exception": false,
     "start_time": "2021-07-20T06:27:51.704157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5c7b5d920f4e2cba24f52653394b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d65f761ed547d6837a46e7847fc411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## fold-0 ##############################\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.028 (0.032) time: 0.274 (0.309) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 1.5560849905014038\n",
      "Epoch[0] [09/141] eta: 0:02:38 train_loss: 1.434 (1.434) time: 1.131 (1.131) data: 0.048 (0.048)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.024 (0.032) time: 0.274 (0.308) data: 0.001 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 1.0819593667984009\n",
      "Epoch[0] [19/141] eta: 0:02:28 train_loss: 1.137 (1.244) time: 1.130 (1.064) data: 0.000 (0.024)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.023) time: 0.273 (0.300) data: 0.000 (0.026)\n",
      "Total time: 0:00:05\n",
      "val_loss: 1.0015506744384766\n",
      "Epoch[0] [29/141] eta: 0:02:24 train_loss: 0.864 (1.107) time: 1.121 (1.033) data: 0.000 (0.016)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.273 (0.313) data: 0.000 (0.039)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.9558019042015076\n",
      "min_loss decreased from 1.0 to 0.9558019042015076.\n",
      "saving model...\n",
      "Epoch[0] [39/141] eta: 0:02:29 train_loss: 0.788 (1.025) time: 1.238 (1.068) data: 0.000 (0.012)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.019) time: 0.273 (0.323) data: 0.000 (0.049)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.8185920715332031\n",
      "min_loss decreased from 0.9558019042015076 to 0.8185920715332031.\n",
      "saving model...\n",
      "Epoch[0] [49/141] eta: 0:02:33 train_loss: 0.662 (0.940) time: 1.387 (1.098) data: 0.000 (0.010)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.021) time: 0.273 (0.308) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.8022691607475281\n",
      "min_loss decreased from 0.8185920715332031 to 0.8022691607475281.\n",
      "saving model...\n",
      "Epoch[0] [59/141] eta: 0:02:36 train_loss: 0.583 (0.883) time: 1.406 (1.114) data: 0.000 (0.008)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.025 (0.030) time: 0.274 (0.304) data: 0.001 (0.030)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.712501049041748\n",
      "min_loss decreased from 0.8022691607475281 to 0.712501049041748.\n",
      "saving model...\n",
      "Epoch[0] [69/141] eta: 0:02:37 train_loss: 0.599 (0.843) time: 1.375 (1.123) data: 0.000 (0.007)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.273 (0.306) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.64204341173172\n",
      "min_loss decreased from 0.712501049041748 to 0.64204341173172.\n",
      "saving model...\n",
      "Epoch[0] [79/141] eta: 0:02:38 train_loss: 0.595 (0.811) time: 1.363 (1.130) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.274 (0.306) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.7269819378852844\n",
      "Epoch[0] [89/141] eta: 0:02:35 train_loss: 0.529 (0.776) time: 1.243 (1.113) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.026 (0.028) time: 0.275 (0.311) data: 0.000 (0.036)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6330558657646179\n",
      "min_loss decreased from 0.64204341173172 to 0.6330558657646179.\n",
      "saving model...\n",
      "Epoch[0] [99/141] eta: 0:02:36 train_loss: 0.482 (0.747) time: 1.246 (1.120) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.026) time: 0.273 (0.317) data: 0.000 (0.044)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.588550329208374\n",
      "min_loss decreased from 0.6330558657646179 to 0.588550329208374.\n",
      "saving model...\n",
      "Epoch[0] [109/141] eta: 0:02:38 train_loss: 0.466 (0.723) time: 1.398 (1.129) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.273 (0.308) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.620969295501709\n",
      "Epoch[0] [119/141] eta: 0:02:36 train_loss: 0.484 (0.704) time: 1.264 (1.116) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.024 (0.029) time: 0.273 (0.323) data: 0.000 (0.049)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6328780651092529\n",
      "Epoch[0] [129/141] eta: 0:02:35 train_loss: 0.506 (0.689) time: 1.135 (1.108) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.273 (0.306) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6021837592124939\n",
      "Epoch[0] [139/141] eta: 0:02:33 train_loss: 0.454 (0.670) time: 1.127 (1.097) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.023) time: 0.274 (0.309) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5933399796485901\n",
      "Epoch[0] [140/141] eta: 0:02:38 train_loss: 0.443 (0.668) time: 1.480 (1.133) data: 0.000 (0.004)\n",
      "Total time: 0:02:39\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.273 (0.302) data: 0.000 (0.028)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5847813487052917\n",
      "min_loss decreased from 0.588550329208374 to 0.5847813487052917.\n",
      "saving model...\n",
      "Epoch[1] [09/141] eta: 0:02:55 train_loss: 0.520 (0.520) time: 1.255 (1.255) data: 0.038 (0.038)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.025) time: 0.273 (0.303) data: 0.000 (0.030)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5796497464179993\n",
      "min_loss decreased from 0.5847813487052917 to 0.5796497464179993.\n",
      "saving model...\n",
      "Epoch[1] [19/141] eta: 0:02:51 train_loss: 0.472 (0.493) time: 1.395 (1.222) data: 0.000 (0.019)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.023) time: 0.274 (0.316) data: 0.000 (0.042)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.579177975654602\n",
      "min_loss decreased from 0.5796497464179993 to 0.579177975654602.\n",
      "saving model...\n",
      "Epoch[1] [29/141] eta: 0:02:49 train_loss: 0.427 (0.467) time: 1.378 (1.213) data: 0.000 (0.013)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.022) time: 0.273 (0.322) data: 0.000 (0.049)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5602115988731384\n",
      "min_loss decreased from 0.579177975654602 to 0.5602115988731384.\n",
      "saving model...\n",
      "Epoch[1] [39/141] eta: 0:02:49 train_loss: 0.436 (0.457) time: 1.402 (1.213) data: 0.000 (0.010)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.021) time: 0.272 (0.308) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5868944525718689\n",
      "Epoch[1] [49/141] eta: 0:02:43 train_loss: 0.467 (0.457) time: 1.269 (1.168) data: 0.000 (0.008)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.023) time: 0.273 (0.318) data: 0.000 (0.045)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5946939587593079\n",
      "Epoch[1] [59/141] eta: 0:02:39 train_loss: 0.449 (0.452) time: 1.134 (1.139) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.025 (0.027) time: 0.275 (0.312) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5430256724357605\n",
      "min_loss decreased from 0.5602115988731384 to 0.5430256724357605.\n",
      "saving model...\n",
      "Epoch[1] [69/141] eta: 0:02:40 train_loss: 0.420 (0.448) time: 1.276 (1.149) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.025) time: 0.273 (0.317) data: 0.000 (0.043)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5706948637962341\n",
      "Epoch[1] [79/141] eta: 0:02:38 train_loss: 0.448 (0.451) time: 1.279 (1.131) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.024 (0.026) time: 0.274 (0.302) data: 0.000 (0.027)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5527932643890381\n",
      "Epoch[1] [89/141] eta: 0:02:35 train_loss: 0.429 (0.446) time: 1.127 (1.113) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.019) time: 0.274 (0.309) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5251515507698059\n",
      "min_loss decreased from 0.5430256724357605 to 0.5251515507698059.\n",
      "saving model...\n",
      "Epoch[1] [99/141] eta: 0:02:36 train_loss: 0.371 (0.439) time: 1.245 (1.121) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.025 (0.031) time: 0.274 (0.313) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5313917994499207\n",
      "Epoch[1] [109/141] eta: 0:02:35 train_loss: 0.367 (0.432) time: 1.263 (1.109) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.019) time: 0.273 (0.318) data: 0.000 (0.045)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5589712858200073\n",
      "Epoch[1] [119/141] eta: 0:02:34 train_loss: 0.377 (0.428) time: 1.140 (1.101) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.021 (0.027) time: 0.273 (0.314) data: 0.000 (0.041)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5690113306045532\n",
      "Epoch[1] [129/141] eta: 0:02:32 train_loss: 0.361 (0.423) time: 1.146 (1.093) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.273 (0.321) data: 0.000 (0.048)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5326351523399353\n",
      "Epoch[1] [139/141] eta: 0:02:32 train_loss: 0.385 (0.421) time: 1.147 (1.086) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.272 (0.309) data: 0.000 (0.036)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5314546823501587\n",
      "Epoch[1] [140/141] eta: 0:02:37 train_loss: 0.381 (0.419) time: 1.498 (1.122) data: 0.000 (0.003)\n",
      "Total time: 0:02:38\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.020) time: 0.272 (0.311) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.8329788446426392\n",
      "Epoch[2] [09/141] eta: 0:02:24 train_loss: 0.505 (0.505) time: 1.031 (1.031) data: 0.033 (0.033)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.023) time: 0.274 (0.316) data: 0.000 (0.042)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6196696758270264\n",
      "Epoch[2] [19/141] eta: 0:02:21 train_loss: 0.436 (0.464) time: 1.136 (1.011) data: 0.000 (0.016)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.024 (0.027) time: 0.274 (0.301) data: 0.000 (0.026)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6004360914230347\n",
      "Epoch[2] [29/141] eta: 0:02:20 train_loss: 0.413 (0.452) time: 1.132 (1.001) data: 0.000 (0.011)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.018) time: 0.273 (0.309) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5388283729553223\n",
      "Epoch[2] [39/141] eta: 0:02:19 train_loss: 0.408 (0.431) time: 1.115 (0.994) data: 0.000 (0.008)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.021) time: 0.273 (0.302) data: 0.000 (0.028)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5231385231018066\n",
      "min_loss decreased from 0.5251515507698059 to 0.5231385231018066.\n",
      "saving model...\n",
      "Epoch[2] [49/141] eta: 0:02:25 train_loss: 0.340 (0.415) time: 1.258 (1.036) data: 0.000 (0.007)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.024) time: 0.273 (0.308) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5482167601585388\n",
      "Epoch[2] [59/141] eta: 0:02:23 train_loss: 0.355 (0.405) time: 1.262 (1.028) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.026) time: 0.273 (0.302) data: 0.000 (0.028)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.549275279045105\n",
      "Epoch[2] [69/141] eta: 0:02:22 train_loss: 0.346 (0.393) time: 1.118 (1.020) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.020) time: 0.273 (0.308) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5547667145729065\n",
      "Epoch[2] [79/141] eta: 0:02:22 train_loss: 0.350 (0.390) time: 1.116 (1.015) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.272 (0.307) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5248585939407349\n",
      "Epoch[2] [89/141] eta: 0:02:21 train_loss: 0.361 (0.385) time: 1.119 (1.011) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.272 (0.305) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5219660997390747\n",
      "min_loss decreased from 0.5231385231018066 to 0.5219660997390747.\n",
      "saving model...\n",
      "Epoch[2] [99/141] eta: 0:02:23 train_loss: 0.352 (0.381) time: 1.240 (1.027) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.272 (0.308) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5250915884971619\n",
      "Epoch[2] [109/141] eta: 0:02:23 train_loss: 0.354 (0.378) time: 1.235 (1.022) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.023 (0.030) time: 0.274 (0.324) data: 0.000 (0.050)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5266410708427429\n",
      "Epoch[2] [119/141] eta: 0:02:23 train_loss: 0.307 (0.372) time: 1.142 (1.021) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.020) time: 0.273 (0.310) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5244772434234619\n",
      "Epoch[2] [129/141] eta: 0:02:22 train_loss: 0.353 (0.372) time: 1.147 (1.019) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.273 (0.306) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5261398553848267\n",
      "Epoch[2] [139/141] eta: 0:02:22 train_loss: 0.334 (0.367) time: 1.117 (1.015) data: 0.000 (0.002)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.023) time: 0.273 (0.302) data: 0.000 (0.029)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5263521671295166\n",
      "Epoch[2] [140/141] eta: 0:02:27 train_loss: 0.332 (0.367) time: 1.461 (1.051) data: 0.000 (0.002)\n",
      "Total time: 0:02:28\n",
      "fold-0: min_loss=0.5219660997390747\n",
      "############################## fold-1 ##############################\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.024) time: 0.269 (0.311) data: 0.000 (0.041)\n",
      "Total time: 0:00:05\n",
      "val_loss: 1.442710280418396\n",
      "Epoch[0] [09/141] eta: 0:02:26 train_loss: 1.369 (1.369) time: 1.048 (1.048) data: 0.036 (0.036)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.024 (0.029) time: 0.270 (0.297) data: 0.000 (0.027)\n",
      "Total time: 0:00:05\n",
      "val_loss: 1.0611780881881714\n",
      "Epoch[0] [19/141] eta: 0:02:21 train_loss: 1.111 (1.177) time: 1.125 (1.011) data: 0.000 (0.018)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.269 (0.303) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.9750659465789795\n",
      "min_loss decreased from 1.0 to 0.9750659465789795.\n",
      "saving model...\n",
      "Epoch[0] [29/141] eta: 0:02:25 train_loss: 0.830 (1.037) time: 1.191 (1.041) data: 0.000 (0.012)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.025 (0.028) time: 0.270 (0.303) data: 0.000 (0.031)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.8965610861778259\n",
      "min_loss decreased from 0.9750659465789795 to 0.8965610861778259.\n",
      "saving model...\n",
      "Epoch[0] [39/141] eta: 0:02:33 train_loss: 0.757 (0.969) time: 1.381 (1.100) data: 0.000 (0.009)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.024) time: 0.268 (0.312) data: 0.000 (0.043)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6803548336029053\n",
      "min_loss decreased from 0.8965610861778259 to 0.6803548336029053.\n",
      "saving model...\n",
      "Epoch[0] [49/141] eta: 0:02:35 train_loss: 0.676 (0.898) time: 1.427 (1.114) data: 0.000 (0.007)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.034 (0.044) time: 0.271 (0.319) data: 0.001 (0.048)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6913024187088013\n",
      "Epoch[0] [59/141] eta: 0:02:33 train_loss: 0.617 (0.858) time: 1.251 (1.096) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.021 (0.025) time: 0.270 (0.310) data: 0.000 (0.040)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6643921136856079\n",
      "min_loss decreased from 0.6803548336029053 to 0.6643921136856079.\n",
      "saving model...\n",
      "Epoch[0] [69/141] eta: 0:02:34 train_loss: 0.600 (0.818) time: 1.253 (1.106) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.269 (0.311) data: 0.000 (0.042)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.615730881690979\n",
      "min_loss decreased from 0.6643921136856079 to 0.615730881690979.\n",
      "saving model...\n",
      "Epoch[0] [79/141] eta: 0:02:35 train_loss: 0.519 (0.780) time: 1.335 (1.111) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.022 (0.028) time: 0.269 (0.314) data: 0.000 (0.044)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6655740737915039\n",
      "Epoch[0] [89/141] eta: 0:02:33 train_loss: 0.504 (0.748) time: 1.231 (1.098) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.023) time: 0.268 (0.303) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6292898058891296\n",
      "Epoch[0] [99/141] eta: 0:02:31 train_loss: 0.506 (0.723) time: 1.125 (1.085) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.021) time: 0.269 (0.304) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5620007514953613\n",
      "min_loss decreased from 0.615730881690979 to 0.5620007514953613.\n",
      "saving model...\n",
      "Epoch[0] [109/141] eta: 0:02:32 train_loss: 0.457 (0.698) time: 1.213 (1.090) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.029 (0.032) time: 0.272 (0.311) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6350695490837097\n",
      "Epoch[0] [119/141] eta: 0:02:31 train_loss: 0.464 (0.678) time: 1.225 (1.082) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.023 (0.028) time: 0.270 (0.296) data: 0.000 (0.026)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5870935320854187\n",
      "Epoch[0] [129/141] eta: 0:02:30 train_loss: 0.469 (0.663) time: 1.115 (1.073) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.269 (0.305) data: 0.000 (0.036)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6311907768249512\n",
      "Epoch[0] [139/141] eta: 0:02:29 train_loss: 0.447 (0.646) time: 1.109 (1.066) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.268 (0.304) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5614776611328125\n",
      "min_loss decreased from 0.5620007514953613 to 0.5614776611328125.\n",
      "saving model...\n",
      "Epoch[0] [140/141] eta: 0:02:35 train_loss: 0.445 (0.645) time: 1.556 (1.113) data: 0.000 (0.003)\n",
      "Total time: 0:02:37\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.021 (0.025) time: 0.269 (0.303) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5802227258682251\n",
      "Epoch[1] [09/141] eta: 0:02:21 train_loss: 0.443 (0.443) time: 1.012 (1.012) data: 0.028 (0.028)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.020) time: 0.268 (0.301) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6329705119132996\n",
      "Epoch[1] [19/141] eta: 0:02:18 train_loss: 0.448 (0.440) time: 1.115 (0.991) data: 0.000 (0.014)\n",
      "Validation [17/18] eta: 0:00:04 inference_time: 0.018 (0.021) time: 0.269 (0.294) data: 0.000 (0.024)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5556868314743042\n",
      "min_loss decreased from 0.5614776611328125 to 0.5556868314743042.\n",
      "saving model...\n",
      "Epoch[1] [29/141] eta: 0:02:25 train_loss: 0.402 (0.428) time: 1.207 (1.037) data: 0.000 (0.009)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.022 (0.028) time: 0.268 (0.323) data: 0.000 (0.053)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5452408194541931\n",
      "min_loss decreased from 0.5556868314743042 to 0.5452408194541931.\n",
      "saving model...\n",
      "Epoch[1] [39/141] eta: 0:02:29 train_loss: 0.425 (0.432) time: 1.331 (1.071) data: 0.000 (0.007)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.023) time: 0.269 (0.303) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5829663872718811\n",
      "Epoch[1] [49/141] eta: 0:02:27 train_loss: 0.434 (0.434) time: 1.240 (1.053) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.020) time: 0.268 (0.300) data: 0.000 (0.031)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5788778066635132\n",
      "Epoch[1] [59/141] eta: 0:02:25 train_loss: 0.420 (0.428) time: 1.116 (1.040) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.025 (0.027) time: 0.271 (0.304) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5385909080505371\n",
      "min_loss decreased from 0.5452408194541931 to 0.5385909080505371.\n",
      "saving model...\n",
      "Epoch[1] [69/141] eta: 0:02:27 train_loss: 0.396 (0.419) time: 1.211 (1.053) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.021 (0.027) time: 0.270 (0.304) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5433950424194336\n",
      "Epoch[1] [79/141] eta: 0:02:25 train_loss: 0.379 (0.412) time: 1.211 (1.042) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.021) time: 0.270 (0.295) data: 0.000 (0.024)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5222468972206116\n",
      "min_loss decreased from 0.5385909080505371 to 0.5222468972206116.\n",
      "saving model...\n",
      "Epoch[1] [89/141] eta: 0:02:27 train_loss: 0.367 (0.407) time: 1.201 (1.050) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.030 (0.035) time: 0.271 (0.304) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5326130986213684\n",
      "Epoch[1] [99/141] eta: 0:02:26 train_loss: 0.382 (0.405) time: 1.202 (1.043) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.269 (0.304) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6118279099464417\n",
      "Epoch[1] [109/141] eta: 0:02:25 train_loss: 0.377 (0.405) time: 1.119 (1.037) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.022) time: 0.268 (0.302) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5192911028862\n",
      "min_loss decreased from 0.5222468972206116 to 0.5192911028862.\n",
      "saving model...\n",
      "Epoch[1] [119/141] eta: 0:02:26 train_loss: 0.395 (0.403) time: 1.215 (1.046) data: 0.000 (0.002)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.025) time: 0.269 (0.302) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.511987030506134\n",
      "min_loss decreased from 0.5192911028862 to 0.511987030506134.\n",
      "saving model...\n",
      "Epoch[1] [129/141] eta: 0:02:27 train_loss: 0.387 (0.401) time: 1.314 (1.053) data: 0.000 (0.002)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.268 (0.300) data: 0.000 (0.030)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5082032084465027\n",
      "min_loss decreased from 0.511987030506134 to 0.5082032084465027.\n",
      "saving model...\n",
      "Epoch[1] [139/141] eta: 0:02:28 train_loss: 0.344 (0.397) time: 1.308 (1.058) data: 0.000 (0.002)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.269 (0.307) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5123487710952759\n",
      "Epoch[1] [140/141] eta: 0:02:33 train_loss: 0.346 (0.396) time: 1.659 (1.093) data: 0.000 (0.002)\n",
      "Total time: 0:02:34\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.269 (0.295) data: 0.000 (0.025)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6365232467651367\n",
      "Epoch[2] [09/141] eta: 0:02:21 train_loss: 0.458 (0.458) time: 1.009 (1.009) data: 0.030 (0.030)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.268 (0.303) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5103737711906433\n",
      "Epoch[2] [19/141] eta: 0:02:19 train_loss: 0.417 (0.432) time: 1.120 (0.999) data: 0.001 (0.016)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.022) time: 0.268 (0.303) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.504381537437439\n",
      "min_loss decreased from 0.5082032084465027 to 0.504381537437439.\n",
      "saving model...\n",
      "Epoch[2] [29/141] eta: 0:02:26 train_loss: 0.381 (0.409) time: 1.229 (1.049) data: 0.001 (0.010)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.269 (0.301) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.517220139503479\n",
      "Epoch[2] [39/141] eta: 0:02:24 train_loss: 0.345 (0.388) time: 1.224 (1.031) data: 0.000 (0.008)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.024) time: 0.268 (0.315) data: 0.000 (0.046)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5337012410163879\n",
      "Epoch[2] [49/141] eta: 0:02:23 train_loss: 0.309 (0.368) time: 1.125 (1.023) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.021 (0.024) time: 0.269 (0.302) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5142046213150024\n",
      "Epoch[2] [59/141] eta: 0:02:22 train_loss: 0.307 (0.361) time: 1.128 (1.015) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.020) time: 0.269 (0.308) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5227078199386597\n",
      "Epoch[2] [69/141] eta: 0:02:21 train_loss: 0.316 (0.354) time: 1.114 (1.010) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.029 (0.031) time: 0.270 (0.295) data: 0.000 (0.025)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5098510980606079\n",
      "Epoch[2] [79/141] eta: 0:02:20 train_loss: 0.283 (0.343) time: 1.101 (1.002) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.020) time: 0.268 (0.298) data: 0.000 (0.029)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5104352831840515\n",
      "Epoch[2] [89/141] eta: 0:02:19 train_loss: 0.295 (0.339) time: 1.096 (0.999) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.019) time: 0.269 (0.301) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.523004949092865\n",
      "Epoch[2] [99/141] eta: 0:02:19 train_loss: 0.313 (0.337) time: 1.100 (0.995) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.022) time: 0.269 (0.295) data: 0.000 (0.026)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5043799877166748\n",
      "min_loss decreased from 0.504381537437439 to 0.5043799877166748.\n",
      "saving model...\n",
      "Epoch[2] [109/141] eta: 0:02:21 train_loss: 0.345 (0.338) time: 1.209 (1.008) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.268 (0.302) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5135777592658997\n",
      "Epoch[2] [119/141] eta: 0:02:20 train_loss: 0.354 (0.337) time: 1.213 (1.006) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.020) time: 0.269 (0.302) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.49851924180984497\n",
      "min_loss decreased from 0.5043799877166748 to 0.49851924180984497.\n",
      "saving model...\n",
      "Epoch[2] [129/141] eta: 0:02:22 train_loss: 0.347 (0.338) time: 1.224 (1.017) data: 0.000 (0.002)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.023) time: 0.268 (0.297) data: 0.000 (0.028)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.4979228377342224\n",
      "min_loss decreased from 0.49851924180984497 to 0.4979228377342224.\n",
      "saving model...\n",
      "Epoch[2] [139/141] eta: 0:02:23 train_loss: 0.317 (0.335) time: 1.307 (1.024) data: 0.000 (0.002)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.024) time: 0.269 (0.311) data: 0.000 (0.041)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.49787238240242004\n",
      "min_loss decreased from 0.4979228377342224 to 0.49787238240242004.\n",
      "saving model...\n",
      "Epoch[2] [140/141] eta: 0:02:29 train_loss: 0.314 (0.335) time: 1.762 (1.071) data: 0.000 (0.002)\n",
      "Total time: 0:02:31\n",
      "fold-1: min_loss=0.49787238240242004\n",
      "############################## fold-2 ##############################\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.268 (0.303) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 1.629159688949585\n",
      "Epoch[0] [09/141] eta: 0:02:27 train_loss: 1.502 (1.502) time: 1.051 (1.051) data: 0.057 (0.057)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.269 (0.305) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 1.1459081172943115\n",
      "Epoch[0] [19/141] eta: 0:02:21 train_loss: 1.210 (1.288) time: 1.123 (1.013) data: 0.000 (0.029)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.020) time: 0.268 (0.307) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.9997341632843018\n",
      "min_loss decreased from 1.0 to 0.9997341632843018.\n",
      "saving model...\n",
      "Epoch[0] [29/141] eta: 0:02:26 train_loss: 0.779 (1.099) time: 1.205 (1.049) data: 0.000 (0.019)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.268 (0.307) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.9410857558250427\n",
      "min_loss decreased from 0.9997341632843018 to 0.9410857558250427.\n",
      "saving model...\n",
      "Epoch[0] [39/141] eta: 0:02:30 train_loss: 0.746 (1.012) time: 1.313 (1.075) data: 0.000 (0.014)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.024) time: 0.269 (0.306) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.7840317487716675\n",
      "min_loss decreased from 0.9410857558250427 to 0.7840317487716675.\n",
      "saving model...\n",
      "Epoch[0] [49/141] eta: 0:02:32 train_loss: 0.718 (0.953) time: 1.329 (1.088) data: 0.000 (0.011)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.268 (0.304) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.8646085262298584\n",
      "Epoch[0] [59/141] eta: 0:02:29 train_loss: 0.657 (0.903) time: 1.222 (1.071) data: 0.000 (0.010)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.268 (0.296) data: 0.000 (0.026)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.7160406708717346\n",
      "min_loss decreased from 0.7840317487716675 to 0.7160406708717346.\n",
      "saving model...\n",
      "Epoch[0] [69/141] eta: 0:02:31 train_loss: 0.609 (0.855) time: 1.214 (1.079) data: 0.000 (0.008)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.022) time: 0.269 (0.301) data: 0.000 (0.030)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.786453902721405\n",
      "Epoch[0] [79/141] eta: 0:02:29 train_loss: 0.585 (0.821) time: 1.203 (1.066) data: 0.000 (0.007)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.268 (0.307) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6862933039665222\n",
      "min_loss decreased from 0.7160406708717346 to 0.6862933039665222.\n",
      "saving model...\n",
      "Epoch[0] [89/141] eta: 0:02:30 train_loss: 0.557 (0.791) time: 1.221 (1.075) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.020) time: 0.269 (0.310) data: 0.000 (0.040)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6343840956687927\n",
      "min_loss decreased from 0.6862933039665222 to 0.6343840956687927.\n",
      "saving model...\n",
      "Epoch[0] [99/141] eta: 0:02:31 train_loss: 0.552 (0.767) time: 1.338 (1.083) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.024) time: 0.269 (0.308) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6204397082328796\n",
      "min_loss decreased from 0.6343840956687927 to 0.6204397082328796.\n",
      "saving model...\n",
      "Epoch[0] [109/141] eta: 0:02:32 train_loss: 0.510 (0.743) time: 1.322 (1.088) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.018) time: 0.268 (0.308) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6746789813041687\n",
      "Epoch[0] [119/141] eta: 0:02:31 train_loss: 0.490 (0.721) time: 1.218 (1.079) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.018) time: 0.268 (0.307) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5779275298118591\n",
      "min_loss decreased from 0.6204397082328796 to 0.5779275298118591.\n",
      "saving model...\n",
      "Epoch[0] [129/141] eta: 0:02:31 train_loss: 0.475 (0.703) time: 1.215 (1.084) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.269 (0.303) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6639828085899353\n",
      "Epoch[0] [139/141] eta: 0:02:30 train_loss: 0.526 (0.691) time: 1.207 (1.075) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.022) time: 0.268 (0.303) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6485238075256348\n",
      "Epoch[0] [140/141] eta: 0:02:35 train_loss: 0.515 (0.689) time: 1.553 (1.110) data: 0.000 (0.004)\n",
      "Total time: 0:02:36\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.268 (0.299) data: 0.000 (0.029)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.7416678667068481\n",
      "Epoch[1] [09/141] eta: 0:02:21 train_loss: 0.498 (0.498) time: 1.012 (1.012) data: 0.034 (0.034)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.020) time: 0.269 (0.306) data: 0.000 (0.036)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6293085217475891\n",
      "Epoch[1] [19/141] eta: 0:02:19 train_loss: 0.525 (0.516) time: 1.116 (0.998) data: 0.000 (0.017)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.018) time: 0.269 (0.308) data: 0.000 (0.039)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6166496872901917\n",
      "Epoch[1] [29/141] eta: 0:02:19 train_loss: 0.476 (0.497) time: 1.124 (0.994) data: 0.000 (0.011)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.268 (0.299) data: 0.000 (0.028)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5756548047065735\n",
      "min_loss decreased from 0.5779275298118591 to 0.5756548047065735.\n",
      "saving model...\n",
      "Epoch[1] [39/141] eta: 0:02:24 train_loss: 0.454 (0.486) time: 1.225 (1.030) data: 0.000 (0.009)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.269 (0.312) data: 0.000 (0.042)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5781696438789368\n",
      "Epoch[1] [49/141] eta: 0:02:23 train_loss: 0.444 (0.477) time: 1.234 (1.025) data: 0.000 (0.007)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.019) time: 0.268 (0.316) data: 0.000 (0.047)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6099716424942017\n",
      "Epoch[1] [59/141] eta: 0:02:23 train_loss: 0.462 (0.472) time: 1.147 (1.022) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.268 (0.302) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5892762541770935\n",
      "Epoch[1] [69/141] eta: 0:02:21 train_loss: 0.414 (0.460) time: 1.121 (1.014) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.016) time: 0.268 (0.307) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5536315441131592\n",
      "min_loss decreased from 0.5756548047065735 to 0.5536315441131592.\n",
      "saving model...\n",
      "Epoch[1] [79/141] eta: 0:02:24 train_loss: 0.369 (0.449) time: 1.219 (1.031) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.024 (0.028) time: 0.269 (0.303) data: 0.001 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.543627142906189\n",
      "min_loss decreased from 0.5536315441131592 to 0.543627142906189.\n",
      "saving model...\n",
      "Epoch[1] [89/141] eta: 0:02:25 train_loss: 0.409 (0.447) time: 1.320 (1.042) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.023) time: 0.269 (0.305) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5859979391098022\n",
      "Epoch[1] [99/141] eta: 0:02:24 train_loss: 0.429 (0.447) time: 1.213 (1.035) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.268 (0.299) data: 0.000 (0.029)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5304250717163086\n",
      "min_loss decreased from 0.543627142906189 to 0.5304250717163086.\n",
      "saving model...\n",
      "Epoch[1] [109/141] eta: 0:02:26 train_loss: 0.389 (0.437) time: 1.214 (1.045) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.026) time: 0.269 (0.327) data: 0.000 (0.057)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5293658375740051\n",
      "min_loss decreased from 0.5304250717163086 to 0.5293658375740051.\n",
      "saving model...\n",
      "Epoch[1] [119/141] eta: 0:02:27 train_loss: 0.345 (0.429) time: 1.346 (1.056) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.021) time: 0.268 (0.304) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.584065854549408\n",
      "Epoch[1] [129/141] eta: 0:02:26 train_loss: 0.357 (0.425) time: 1.239 (1.049) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.017) time: 0.268 (0.308) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.612165093421936\n",
      "Epoch[1] [139/141] eta: 0:02:26 train_loss: 0.374 (0.422) time: 1.114 (1.044) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.023) time: 0.269 (0.300) data: 0.000 (0.030)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5936979055404663\n",
      "Epoch[1] [140/141] eta: 0:02:31 train_loss: 0.369 (0.421) time: 1.460 (1.079) data: 0.000 (0.002)\n",
      "Total time: 0:02:32\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.268 (0.305) data: 0.000 (0.036)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.7677375078201294\n",
      "Epoch[2] [09/141] eta: 0:02:23 train_loss: 0.414 (0.414) time: 1.028 (1.028) data: 0.032 (0.032)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.268 (0.301) data: 0.000 (0.031)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5769414305686951\n",
      "Epoch[2] [19/141] eta: 0:02:19 train_loss: 0.451 (0.434) time: 1.117 (0.996) data: 0.000 (0.016)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.268 (0.308) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5751381516456604\n",
      "Epoch[2] [29/141] eta: 0:02:19 train_loss: 0.392 (0.404) time: 1.117 (0.994) data: 0.000 (0.011)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.020) time: 0.268 (0.301) data: 0.000 (0.031)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5690812468528748\n",
      "Epoch[2] [39/141] eta: 0:02:18 train_loss: 0.331 (0.383) time: 1.124 (0.991) data: 0.000 (0.008)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.269 (0.301) data: 0.000 (0.031)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5376887917518616\n",
      "Epoch[2] [49/141] eta: 0:02:18 train_loss: 0.347 (0.379) time: 1.114 (0.988) data: 0.000 (0.007)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.269 (0.304) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5370023250579834\n",
      "Epoch[2] [59/141] eta: 0:02:17 train_loss: 0.309 (0.365) time: 1.108 (0.985) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.025) time: 0.270 (0.328) data: 0.000 (0.057)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5545258522033691\n",
      "Epoch[2] [69/141] eta: 0:02:18 train_loss: 0.298 (0.356) time: 1.136 (0.989) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.269 (0.304) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5507362484931946\n",
      "Epoch[2] [79/141] eta: 0:02:18 train_loss: 0.316 (0.352) time: 1.139 (0.987) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.023) time: 0.269 (0.299) data: 0.000 (0.028)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5369469523429871\n",
      "Epoch[2] [89/141] eta: 0:02:18 train_loss: 0.289 (0.342) time: 1.115 (0.986) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.022 (0.025) time: 0.270 (0.299) data: 0.001 (0.029)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5240855813026428\n",
      "min_loss decreased from 0.5293658375740051 to 0.5240855813026428.\n",
      "saving model...\n",
      "Epoch[2] [99/141] eta: 0:02:20 train_loss: 0.312 (0.342) time: 1.210 (1.001) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.020) time: 0.268 (0.303) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.522494912147522\n",
      "min_loss decreased from 0.5240855813026428 to 0.522494912147522.\n",
      "saving model...\n",
      "Epoch[2] [109/141] eta: 0:02:21 train_loss: 0.318 (0.338) time: 1.318 (1.013) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.268 (0.306) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5282527208328247\n",
      "Epoch[2] [119/141] eta: 0:02:21 train_loss: 0.296 (0.335) time: 1.213 (1.010) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.021 (0.023) time: 0.270 (0.308) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.527873694896698\n",
      "Epoch[2] [129/141] eta: 0:02:21 train_loss: 0.314 (0.334) time: 1.121 (1.008) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.022) time: 0.269 (0.300) data: 0.000 (0.029)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5286084413528442\n",
      "Epoch[2] [139/141] eta: 0:02:20 train_loss: 0.311 (0.333) time: 1.117 (1.005) data: 0.000 (0.002)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.024 (0.029) time: 0.269 (0.302) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5284411907196045\n",
      "Epoch[2] [140/141] eta: 0:02:25 train_loss: 0.298 (0.332) time: 1.464 (1.040) data: 0.000 (0.002)\n",
      "Total time: 0:02:26\n",
      "fold-2: min_loss=0.522494912147522\n",
      "############################## fold-3 ##############################\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.022) time: 0.271 (0.314) data: 0.000 (0.041)\n",
      "Total time: 0:00:05\n",
      "val_loss: 1.2037009000778198\n",
      "Epoch[0] [09/141] eta: 0:02:27 train_loss: 1.025 (1.025) time: 1.051 (1.051) data: 0.032 (0.032)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.019) time: 0.271 (0.311) data: 0.000 (0.039)\n",
      "Total time: 0:00:05\n",
      "val_loss: 1.0282961130142212\n",
      "Epoch[0] [19/141] eta: 0:02:22 train_loss: 0.887 (0.898) time: 1.135 (1.017) data: 0.000 (0.016)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.020) time: 0.272 (0.312) data: 0.000 (0.039)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.9615657925605774\n",
      "min_loss decreased from 1.0 to 0.9615657925605774.\n",
      "saving model...\n",
      "Epoch[0] [29/141] eta: 0:02:27 train_loss: 0.775 (0.865) time: 1.218 (1.055) data: 0.000 (0.011)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.022 (0.024) time: 0.272 (0.311) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.7899474501609802\n",
      "min_loss decreased from 0.9615657925605774 to 0.7899474501609802.\n",
      "saving model...\n",
      "Epoch[0] [39/141] eta: 0:02:32 train_loss: 0.763 (0.829) time: 1.349 (1.092) data: 0.000 (0.008)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.020) time: 0.271 (0.303) data: 0.000 (0.031)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.7796837091445923\n",
      "min_loss decreased from 0.7899474501609802 to 0.7796837091445923.\n",
      "saving model...\n",
      "Epoch[0] [49/141] eta: 0:02:34 train_loss: 0.649 (0.788) time: 1.354 (1.101) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.272 (0.310) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.7187220454216003\n",
      "min_loss decreased from 0.7796837091445923 to 0.7187220454216003.\n",
      "saving model...\n",
      "Epoch[0] [59/141] eta: 0:02:35 train_loss: 0.575 (0.746) time: 1.323 (1.109) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.024) time: 0.273 (0.311) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6686860918998718\n",
      "min_loss decreased from 0.7187220454216003 to 0.6686860918998718.\n",
      "saving model...\n",
      "Epoch[0] [69/141] eta: 0:02:36 train_loss: 0.500 (0.712) time: 1.333 (1.115) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.022) time: 0.271 (0.303) data: 0.000 (0.031)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6345797181129456\n",
      "min_loss decreased from 0.6686860918998718 to 0.6345797181129456.\n",
      "saving model...\n",
      "Epoch[0] [79/141] eta: 0:02:36 train_loss: 0.491 (0.681) time: 1.338 (1.120) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.020) time: 0.272 (0.310) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6526128053665161\n",
      "Epoch[0] [89/141] eta: 0:02:34 train_loss: 0.500 (0.662) time: 1.233 (1.106) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.028 (0.032) time: 0.274 (0.306) data: 0.001 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.7871943712234497\n",
      "Epoch[0] [99/141] eta: 0:02:33 train_loss: 0.530 (0.651) time: 1.128 (1.094) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.018) time: 0.271 (0.306) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6531190276145935\n",
      "Epoch[0] [109/141] eta: 0:02:31 train_loss: 0.522 (0.639) time: 1.115 (1.083) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.020) time: 0.271 (0.306) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6123306751251221\n",
      "min_loss decreased from 0.6345797181129456 to 0.6123306751251221.\n",
      "saving model...\n",
      "Epoch[0] [119/141] eta: 0:02:32 train_loss: 0.467 (0.624) time: 1.215 (1.087) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.023) time: 0.272 (0.308) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.592646062374115\n",
      "min_loss decreased from 0.6123306751251221 to 0.592646062374115.\n",
      "saving model...\n",
      "Epoch[0] [129/141] eta: 0:02:32 train_loss: 0.451 (0.610) time: 1.323 (1.092) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.271 (0.304) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5588953495025635\n",
      "min_loss decreased from 0.592646062374115 to 0.5588953495025635.\n",
      "saving model...\n",
      "Epoch[0] [139/141] eta: 0:02:33 train_loss: 0.455 (0.599) time: 1.325 (1.095) data: 0.000 (0.002)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.025) time: 0.272 (0.301) data: 0.000 (0.028)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6008777618408203\n",
      "Epoch[0] [140/141] eta: 0:02:38 train_loss: 0.455 (0.598) time: 1.670 (1.130) data: 0.000 (0.002)\n",
      "Total time: 0:02:39\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.024) time: 0.273 (0.310) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5953783988952637\n",
      "Epoch[1] [09/141] eta: 0:02:23 train_loss: 0.475 (0.475) time: 1.026 (1.026) data: 0.032 (0.032)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.021) time: 0.272 (0.302) data: 0.000 (0.029)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5770274996757507\n",
      "Epoch[1] [19/141] eta: 0:02:23 train_loss: 0.480 (0.471) time: 1.153 (1.024) data: 0.000 (0.016)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.020) time: 0.272 (0.306) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5581767559051514\n",
      "min_loss decreased from 0.5588953495025635 to 0.5581767559051514.\n",
      "saving model...\n",
      "Epoch[1] [29/141] eta: 0:02:28 train_loss: 0.429 (0.449) time: 1.244 (1.062) data: 0.000 (0.011)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.022) time: 0.272 (0.303) data: 0.000 (0.031)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6061981916427612\n",
      "Epoch[1] [39/141] eta: 0:02:25 train_loss: 0.347 (0.415) time: 1.208 (1.037) data: 0.000 (0.008)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.018) time: 0.272 (0.319) data: 0.000 (0.046)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6621300578117371\n",
      "Epoch[1] [49/141] eta: 0:02:24 train_loss: 0.403 (0.421) time: 1.119 (1.029) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.272 (0.306) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5704712867736816\n",
      "Epoch[1] [59/141] eta: 0:02:22 train_loss: 0.414 (0.417) time: 1.129 (1.021) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.020) time: 0.271 (0.313) data: 0.000 (0.041)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6035560965538025\n",
      "Epoch[1] [69/141] eta: 0:02:22 train_loss: 0.370 (0.411) time: 1.125 (1.017) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.022 (0.023) time: 0.274 (0.313) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5972476601600647\n",
      "Epoch[1] [79/141] eta: 0:02:21 train_loss: 0.396 (0.410) time: 1.134 (1.014) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.021) time: 0.271 (0.303) data: 0.000 (0.031)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5731165409088135\n",
      "Epoch[1] [89/141] eta: 0:02:21 train_loss: 0.402 (0.405) time: 1.120 (1.009) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.024) time: 0.272 (0.303) data: 0.000 (0.030)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5362069606781006\n",
      "min_loss decreased from 0.5581767559051514 to 0.5362069606781006.\n",
      "saving model...\n",
      "Epoch[1] [99/141] eta: 0:02:22 train_loss: 0.349 (0.400) time: 1.212 (1.021) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.025) time: 0.272 (0.311) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5603246092796326\n",
      "Epoch[1] [109/141] eta: 0:02:22 train_loss: 0.370 (0.397) time: 1.225 (1.018) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.020) time: 0.272 (0.304) data: 0.000 (0.031)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5240609049797058\n",
      "min_loss decreased from 0.5362069606781006 to 0.5240609049797058.\n",
      "saving model...\n",
      "Epoch[1] [119/141] eta: 0:02:23 train_loss: 0.365 (0.393) time: 1.222 (1.028) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.025) time: 0.272 (0.312) data: 0.000 (0.040)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5736266374588013\n",
      "Epoch[1] [129/141] eta: 0:02:23 train_loss: 0.357 (0.389) time: 1.220 (1.025) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.272 (0.310) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5323318243026733\n",
      "Epoch[1] [139/141] eta: 0:02:23 train_loss: 0.369 (0.387) time: 1.140 (1.023) data: 0.000 (0.002)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.019) time: 0.272 (0.312) data: 0.000 (0.039)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5577993988990784\n",
      "Epoch[1] [140/141] eta: 0:02:28 train_loss: 0.366 (0.387) time: 1.494 (1.059) data: 0.000 (0.002)\n",
      "Total time: 0:02:29\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.271 (0.299) data: 0.000 (0.027)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.7845154404640198\n",
      "Epoch[2] [09/141] eta: 0:02:21 train_loss: 0.502 (0.502) time: 1.009 (1.009) data: 0.036 (0.036)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.019) time: 0.271 (0.308) data: 0.000 (0.036)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6107989549636841\n",
      "Epoch[2] [19/141] eta: 0:02:19 train_loss: 0.460 (0.473) time: 1.113 (0.993) data: 0.000 (0.018)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.023 (0.027) time: 0.274 (0.311) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6146965622901917\n",
      "Epoch[2] [29/141] eta: 0:02:18 train_loss: 0.392 (0.445) time: 1.125 (0.992) data: 0.000 (0.012)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.020) time: 0.271 (0.315) data: 0.000 (0.042)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5517637729644775\n",
      "Epoch[2] [39/141] eta: 0:02:19 train_loss: 0.381 (0.424) time: 1.149 (0.998) data: 0.000 (0.009)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.021 (0.027) time: 0.273 (0.312) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5278748273849487\n",
      "Epoch[2] [49/141] eta: 0:02:19 train_loss: 0.362 (0.412) time: 1.148 (0.997) data: 0.000 (0.007)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.273 (0.314) data: 0.000 (0.040)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5264095067977905\n",
      "Epoch[2] [59/141] eta: 0:02:19 train_loss: 0.349 (0.401) time: 1.134 (0.996) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.272 (0.310) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.522958517074585\n",
      "min_loss decreased from 0.5240609049797058 to 0.522958517074585.\n",
      "saving model...\n",
      "Epoch[2] [69/141] eta: 0:02:22 train_loss: 0.334 (0.390) time: 1.227 (1.017) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.021 (0.025) time: 0.272 (0.307) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5238213539123535\n",
      "Epoch[2] [79/141] eta: 0:02:21 train_loss: 0.320 (0.382) time: 1.230 (1.013) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.024) time: 0.271 (0.306) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5179253816604614\n",
      "min_loss decreased from 0.522958517074585 to 0.5179253816604614.\n",
      "saving model...\n",
      "Epoch[2] [89/141] eta: 0:02:23 train_loss: 0.311 (0.374) time: 1.224 (1.028) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.272 (0.310) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5228714942932129\n",
      "Epoch[2] [99/141] eta: 0:02:23 train_loss: 0.289 (0.367) time: 1.222 (1.023) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.021) time: 0.272 (0.303) data: 0.000 (0.030)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5219205021858215\n",
      "Epoch[2] [109/141] eta: 0:02:22 train_loss: 0.316 (0.364) time: 1.119 (1.019) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.018) time: 0.271 (0.310) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5203714966773987\n",
      "Epoch[2] [119/141] eta: 0:02:22 train_loss: 0.328 (0.359) time: 1.120 (1.016) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.271 (0.306) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5149050951004028\n",
      "min_loss decreased from 0.5179253816604614 to 0.5149050951004028.\n",
      "saving model...\n",
      "Epoch[2] [129/141] eta: 0:02:23 train_loss: 0.338 (0.357) time: 1.231 (1.026) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.271 (0.304) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5142037868499756\n",
      "min_loss decreased from 0.5149050951004028 to 0.5142037868499756.\n",
      "saving model...\n",
      "Epoch[2] [139/141] eta: 0:02:25 train_loss: 0.288 (0.349) time: 1.336 (1.036) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.022) time: 0.271 (0.309) data: 0.000 (0.036)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.514179527759552\n",
      "min_loss decreased from 0.5142037868499756 to 0.514179527759552.\n",
      "saving model...\n",
      "Epoch[2] [140/141] eta: 0:02:31 train_loss: 0.289 (0.349) time: 1.795 (1.084) data: 0.000 (0.003)\n",
      "Total time: 0:02:32\n",
      "fold-3: min_loss=0.514179527759552\n",
      "############################## fold-4 ##############################\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.023) time: 0.267 (0.303) data: 0.001 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 1.3421982526779175\n",
      "Epoch[0] [09/141] eta: 0:02:27 train_loss: 1.133 (1.133) time: 1.051 (1.051) data: 0.056 (0.056)\n",
      "Validation [17/18] eta: 0:00:04 inference_time: 0.018 (0.021) time: 0.266 (0.292) data: 0.000 (0.025)\n",
      "Total time: 0:00:05\n",
      "val_loss: 1.0312552452087402\n",
      "Epoch[0] [19/141] eta: 0:02:19 train_loss: 0.996 (1.040) time: 1.100 (0.999) data: 0.000 (0.028)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.020) time: 0.265 (0.301) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.9691352844238281\n",
      "min_loss decreased from 1.0 to 0.9691352844238281.\n",
      "saving model...\n",
      "Epoch[0] [29/141] eta: 0:02:25 train_loss: 0.787 (0.945) time: 1.189 (1.039) data: 0.000 (0.019)\n",
      "Validation [17/18] eta: 0:00:04 inference_time: 0.019 (0.023) time: 0.266 (0.293) data: 0.000 (0.026)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.9763352870941162\n",
      "Epoch[0] [39/141] eta: 0:02:22 train_loss: 0.744 (0.890) time: 1.190 (1.017) data: 0.000 (0.014)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.017) time: 0.266 (0.305) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.768787145614624\n",
      "min_loss decreased from 0.9691352844238281 to 0.768787145614624.\n",
      "saving model...\n",
      "Epoch[0] [49/141] eta: 0:02:25 train_loss: 0.677 (0.843) time: 1.209 (1.043) data: 0.000 (0.011)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.266 (0.303) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.7998996376991272\n",
      "Epoch[0] [59/141] eta: 0:02:24 train_loss: 0.611 (0.802) time: 1.221 (1.031) data: 0.000 (0.009)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.020) time: 0.266 (0.306) data: 0.000 (0.039)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6649260520935059\n",
      "min_loss decreased from 0.768787145614624 to 0.6649260520935059.\n",
      "saving model...\n",
      "Epoch[0] [69/141] eta: 0:02:26 train_loss: 0.573 (0.769) time: 1.225 (1.048) data: 0.000 (0.008)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.022) time: 0.266 (0.301) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6798095107078552\n",
      "Epoch[0] [79/141] eta: 0:02:25 train_loss: 0.544 (0.739) time: 1.225 (1.039) data: 0.000 (0.007)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.019) time: 0.265 (0.302) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6958395838737488\n",
      "Epoch[0] [89/141] eta: 0:02:24 train_loss: 0.575 (0.720) time: 1.108 (1.031) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.020) time: 0.266 (0.300) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.714732825756073\n",
      "Epoch[0] [99/141] eta: 0:02:23 train_loss: 0.540 (0.698) time: 1.114 (1.026) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.026) time: 0.266 (0.296) data: 0.000 (0.029)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6675135493278503\n",
      "Epoch[0] [109/141] eta: 0:02:22 train_loss: 0.510 (0.682) time: 1.109 (1.021) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.267 (0.303) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6099460124969482\n",
      "min_loss decreased from 0.6649260520935059 to 0.6099460124969482.\n",
      "saving model...\n",
      "Epoch[0] [119/141] eta: 0:02:24 train_loss: 0.505 (0.667) time: 1.213 (1.031) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.021 (0.026) time: 0.266 (0.295) data: 0.000 (0.028)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.6471844911575317\n",
      "Epoch[0] [129/141] eta: 0:02:23 train_loss: 0.503 (0.653) time: 1.208 (1.025) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.023) time: 0.265 (0.298) data: 0.000 (0.031)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5990973114967346\n",
      "min_loss decreased from 0.6099460124969482 to 0.5990973114967346.\n",
      "saving model...\n",
      "Epoch[0] [139/141] eta: 0:02:24 train_loss: 0.462 (0.638) time: 1.198 (1.033) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.018) time: 0.265 (0.302) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5747601985931396\n",
      "min_loss decreased from 0.5990973114967346 to 0.5747601985931396.\n",
      "saving model...\n",
      "Epoch[0] [140/141] eta: 0:02:31 train_loss: 0.468 (0.638) time: 1.650 (1.080) data: 0.000 (0.004)\n",
      "Total time: 0:02:32\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.023 (0.026) time: 0.267 (0.301) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5823765993118286\n",
      "Epoch[1] [09/141] eta: 0:02:24 train_loss: 0.487 (0.487) time: 1.029 (1.029) data: 0.040 (0.040)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.016) time: 0.265 (0.307) data: 0.000 (0.040)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5986331105232239\n",
      "Epoch[1] [19/141] eta: 0:02:20 train_loss: 0.480 (0.467) time: 1.118 (1.004) data: 0.000 (0.020)\n",
      "Validation [17/18] eta: 0:00:04 inference_time: 0.016 (0.021) time: 0.266 (0.293) data: 0.000 (0.026)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5823080539703369\n",
      "Epoch[1] [29/141] eta: 0:02:17 train_loss: 0.452 (0.463) time: 1.101 (0.986) data: 0.000 (0.013)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.022) time: 0.266 (0.303) data: 0.000 (0.036)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5970263481140137\n",
      "Epoch[1] [39/141] eta: 0:02:17 train_loss: 0.445 (0.460) time: 1.102 (0.984) data: 0.000 (0.010)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.266 (0.300) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5984562635421753\n",
      "Epoch[1] [49/141] eta: 0:02:17 train_loss: 0.440 (0.454) time: 1.114 (0.981) data: 0.000 (0.008)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.025) time: 0.266 (0.301) data: 0.001 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5730111002922058\n",
      "min_loss decreased from 0.5747601985931396 to 0.5730111002922058.\n",
      "saving model...\n",
      "Epoch[1] [59/141] eta: 0:02:20 train_loss: 0.413 (0.445) time: 1.211 (1.006) data: 0.000 (0.007)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.023 (0.029) time: 0.267 (0.304) data: 0.000 (0.035)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5757575035095215\n",
      "Epoch[1] [69/141] eta: 0:02:20 train_loss: 0.411 (0.440) time: 1.216 (1.003) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.022) time: 0.266 (0.308) data: 0.000 (0.040)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5366525650024414\n",
      "min_loss decreased from 0.5730111002922058 to 0.5366525650024414.\n",
      "saving model...\n",
      "Epoch[1] [79/141] eta: 0:02:22 train_loss: 0.431 (0.444) time: 1.226 (1.021) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.024) time: 0.267 (0.306) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5990980863571167\n",
      "Epoch[1] [89/141] eta: 0:02:22 train_loss: 0.485 (0.446) time: 1.230 (1.017) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.019 (0.022) time: 0.267 (0.302) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5747622847557068\n",
      "Epoch[1] [99/141] eta: 0:02:21 train_loss: 0.415 (0.440) time: 1.116 (1.013) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:04 inference_time: 0.018 (0.022) time: 0.266 (0.294) data: 0.000 (0.025)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5431851744651794\n",
      "Epoch[1] [109/141] eta: 0:02:20 train_loss: 0.396 (0.437) time: 1.096 (1.007) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.020) time: 0.266 (0.299) data: 0.000 (0.032)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.527987539768219\n",
      "min_loss decreased from 0.5366525650024414 to 0.527987539768219.\n",
      "saving model...\n",
      "Epoch[1] [119/141] eta: 0:02:22 train_loss: 0.405 (0.433) time: 1.206 (1.018) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.265 (0.297) data: 0.000 (0.030)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.53682541847229\n",
      "Epoch[1] [129/141] eta: 0:02:21 train_loss: 0.395 (0.430) time: 1.204 (1.014) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.266 (0.312) data: 0.000 (0.044)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.535500705242157\n",
      "Epoch[1] [139/141] eta: 0:02:21 train_loss: 0.399 (0.428) time: 1.112 (1.012) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.022) time: 0.266 (0.304) data: 0.000 (0.037)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5556313991546631\n",
      "Epoch[1] [140/141] eta: 0:02:26 train_loss: 0.403 (0.428) time: 1.463 (1.047) data: 0.000 (0.003)\n",
      "Total time: 0:02:27\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.024) time: 0.267 (0.302) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.7554458379745483\n",
      "Epoch[2] [09/141] eta: 0:02:23 train_loss: 0.426 (0.426) time: 1.027 (1.027) data: 0.033 (0.033)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.022) time: 0.266 (0.302) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.595626950263977\n",
      "Epoch[2] [19/141] eta: 0:02:19 train_loss: 0.450 (0.444) time: 1.116 (0.999) data: 0.000 (0.016)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.020) time: 0.266 (0.301) data: 0.000 (0.033)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5595393180847168\n",
      "Epoch[2] [29/141] eta: 0:02:18 train_loss: 0.420 (0.431) time: 1.110 (0.992) data: 0.000 (0.011)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.020) time: 0.265 (0.296) data: 0.000 (0.029)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5351753234863281\n",
      "Epoch[2] [39/141] eta: 0:02:17 train_loss: 0.388 (0.413) time: 1.099 (0.984) data: 0.000 (0.008)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.019) time: 0.266 (0.303) data: 0.000 (0.036)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5252838730812073\n",
      "min_loss decreased from 0.527987539768219 to 0.5252838730812073.\n",
      "saving model...\n",
      "Epoch[2] [49/141] eta: 0:02:23 train_loss: 0.363 (0.404) time: 1.235 (1.023) data: 0.000 (0.007)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.025) time: 0.266 (0.302) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5343692302703857\n",
      "Epoch[2] [59/141] eta: 0:02:22 train_loss: 0.377 (0.398) time: 1.247 (1.017) data: 0.000 (0.006)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.020) time: 0.266 (0.307) data: 0.000 (0.039)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.534546971321106\n",
      "Epoch[2] [69/141] eta: 0:02:21 train_loss: 0.363 (0.392) time: 1.124 (1.011) data: 0.000 (0.005)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.019) time: 0.266 (0.296) data: 0.000 (0.029)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5338190197944641\n",
      "Epoch[2] [79/141] eta: 0:02:20 train_loss: 0.357 (0.386) time: 1.110 (1.005) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.015 (0.018) time: 0.266 (0.305) data: 0.000 (0.038)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5305688977241516\n",
      "Epoch[2] [89/141] eta: 0:02:20 train_loss: 0.355 (0.382) time: 1.112 (1.004) data: 0.000 (0.004)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.021) time: 0.266 (0.294) data: 0.000 (0.027)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5189434289932251\n",
      "min_loss decreased from 0.5252838730812073 to 0.5189434289932251.\n",
      "saving model...\n",
      "Epoch[2] [99/141] eta: 0:02:22 train_loss: 0.338 (0.377) time: 1.211 (1.015) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.021) time: 0.266 (0.296) data: 0.000 (0.028)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5169620513916016\n",
      "min_loss decreased from 0.5189434289932251 to 0.5169620513916016.\n",
      "saving model...\n",
      "Epoch[2] [109/141] eta: 0:02:23 train_loss: 0.340 (0.374) time: 1.301 (1.026) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.017 (0.022) time: 0.267 (0.295) data: 0.000 (0.027)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5137196779251099\n",
      "min_loss decreased from 0.5169620513916016 to 0.5137196779251099.\n",
      "saving model...\n",
      "Epoch[2] [119/141] eta: 0:02:25 train_loss: 0.316 (0.368) time: 1.329 (1.038) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.020 (0.023) time: 0.266 (0.298) data: 0.000 (0.031)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.513275146484375\n",
      "min_loss decreased from 0.5137196779251099 to 0.513275146484375.\n",
      "saving model...\n",
      "Epoch[2] [129/141] eta: 0:02:26 train_loss: 0.302 (0.364) time: 1.330 (1.045) data: 0.000 (0.003)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.016 (0.021) time: 0.266 (0.301) data: 0.000 (0.034)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5136304497718811\n",
      "Epoch[2] [139/141] eta: 0:02:26 train_loss: 0.308 (0.361) time: 1.237 (1.043) data: 0.000 (0.002)\n",
      "Validation [17/18] eta: 0:00:05 inference_time: 0.018 (0.021) time: 0.266 (0.305) data: 0.000 (0.036)\n",
      "Total time: 0:00:05\n",
      "val_loss: 0.5136922597885132\n",
      "Epoch[2] [140/141] eta: 0:02:30 train_loss: 0.309 (0.360) time: 1.585 (1.078) data: 0.000 (0.002)\n",
      "Total time: 0:02:32\n",
      "fold-4: min_loss=0.513275146484375\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "for fold in range(num_folds):\n",
    "    \n",
    "    train_df = df[(df.fold != fold)].reset_index(drop=True)\n",
    "    val_df = df[(df.fold == fold)].reset_index(drop=True)\n",
    "    \n",
    "    counter = dict(Counter(train_df['bin']))\n",
    "    weights = [counter[i] for i in train_df['bin']]\n",
    "    \n",
    "    train_dataset = CLRPDataset(train_df['excerpt'], train_df['target'])\n",
    "    val_dataset = CLRPDataset(val_df['excerpt'], val_df['target'])\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                  sampler=WeightedRandomSampler(weights, \n",
    "                                                                len(train_df)),\n",
    "                                  collate_fn = CLRPCollate(),\n",
    "                                  num_workers=4, pin_memory=True, drop_last=True)\n",
    "    \n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=2 * batch_size,\n",
    "                            collate_fn = CLRPCollate(),\n",
    "                            shuffle=False,num_workers=4, pin_memory=True)\n",
    "    \n",
    "    # model definition\n",
    "    \n",
    "    model = CLRPModel()\n",
    "    model.to(device)\n",
    "    \n",
    "    lr = 2e-5\n",
    "    epochs = 3\n",
    "    eval_steps = 10\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr, betas=(0.9, 0.999), \n",
    "                      weight_decay=1e-2)\n",
    "    train_steps = len(train_dataset) // batch_size * epochs\n",
    "    num_steps = int(train_steps * 0.1)\n",
    "    lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, \n",
    "                                                   train_steps)\n",
    "    min_loss = 1.0\n",
    "    print('#' * 30, f'fold-{fold}', '#' * 30)\n",
    "    for epoch in range(epochs):\n",
    "        min_loss = train_eval_one_epoch(fold, epoch, train_dataloader, val_dataloader,\\\n",
    "                                        eval_steps, min_loss, model, optimizer, lr_scheduler)\n",
    "    print(f'fold-{fold}: min_loss={min_loss}')\n",
    "    \n",
    "    del model, optimizer, lr_scheduler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2370.458127,
   "end_time": "2021-07-20T07:07:03.958989",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-20T06:27:33.500862",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f2703c05526480189773df6d84f412d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15bd150be6eb4c1c94f6f6629ff7ccee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b913cebf1ecb4ff7bedcc8a53146b2d0",
       "max": 898823.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_850fb3798a5d49f38d040f80583c7e21",
       "value": 898823.0
      }
     },
     "17af4e88698944519d9c85a44939242d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0f2703c05526480189773df6d84f412d",
       "placeholder": "",
       "style": "IPY_MODEL_2b5a5822698149afb9f42025c4ba3410",
       "value": "Downloading: 100%"
      }
     },
     "17b9cf72c34542459f2046abc2bc87e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b8915d9cdd44180a64144725dd2c288": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1d5c7b5d920f4e2cba24f52653394b77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_17af4e88698944519d9c85a44939242d",
        "IPY_MODEL_81c0c821b71e4c8ea4ca68cd41d18ffe",
        "IPY_MODEL_87b2e5c1100f41f28eed7475e12673be"
       ],
       "layout": "IPY_MODEL_355966a2a7434d4d9a7f44ac2e81b046"
      }
     },
     "1d80e55b41d4419c948c43dae22ef847": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1f264b544f61441f98ced65713c80c37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "21aa5e1143154e899c3c2edfda396118": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b5a5822698149afb9f42025c4ba3410": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2b699d575fae4fdd90dafef7c68098bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "342644bc18e44735b51eb1a5f8e58cba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_aaf133f790dd411b84c6d33e2e59e469",
        "IPY_MODEL_9e0ea0adfbc247feb840c73c43648f78",
        "IPY_MODEL_52d47ee33bad47b8907d212c261c62b4"
       ],
       "layout": "IPY_MODEL_ab0f35a216424784a26acd9b916b48db"
      }
     },
     "355966a2a7434d4d9a7f44ac2e81b046": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "37e34f1a35d64d91bff35c00397fe46d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_eecdc8c20e6f4262ae8ddd24cceb2229",
       "max": 456318.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e6fa03d85192487b8bcbc14fce2f6274",
       "value": 456318.0
      }
     },
     "395d939f88dd4f6cb6ecd59478551f38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_17b9cf72c34542459f2046abc2bc87e1",
       "placeholder": "",
       "style": "IPY_MODEL_90312a6b09714938ae53a665a83dc151",
       "value": "Downloading: 100%"
      }
     },
     "3a6565aa2933488d89f1c22345a46a34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "44b63cfdfd8e4dd7ac02e4f3883d69b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ee75ec53c5145628a57b173e6accf53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d46a7cdc22f14933a3abb33437491c89",
       "placeholder": "",
       "style": "IPY_MODEL_2b699d575fae4fdd90dafef7c68098bb",
       "value": "Downloading: 100%"
      }
     },
     "52a9699aaee442a780b8355ecd02ac3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_21aa5e1143154e899c3c2edfda396118",
       "max": 501200538.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_754ce890454e4ed89ed3ab82ba4647da",
       "value": 501200538.0
      }
     },
     "52d47ee33bad47b8907d212c261c62b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_690e1048a3024e50b0a8e32defbd262d",
       "placeholder": "",
       "style": "IPY_MODEL_d64fda070b884916b85ad57cfaabcb7a",
       "value": " 1.36M/1.36M [00:00&lt;00:00, 4.75MB/s]"
      }
     },
     "5af3b34595994ba8affa88e0960a88a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e2df47b82a44452ebb5867f0f189c796",
       "placeholder": "",
       "style": "IPY_MODEL_8afbabe746014c61b584d0ac88074b3e",
       "value": " 501M/501M [00:22&lt;00:00, 23.2MB/s]"
      }
     },
     "5b854711e5e743168ce764f5ce66fa72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4ee75ec53c5145628a57b173e6accf53",
        "IPY_MODEL_15bd150be6eb4c1c94f6f6629ff7ccee",
        "IPY_MODEL_cb3f3bf79f49434ab9274d1d909e49cb"
       ],
       "layout": "IPY_MODEL_a9737b19871a480ea2e16060a765e8fd"
      }
     },
     "5df179642d9645aeb840a9cd313b9593": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "61d910b253034a97b5af881ec7986453": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "690e1048a3024e50b0a8e32defbd262d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "754ce890454e4ed89ed3ab82ba4647da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "77b6f0902d154353957e96eb29366d03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ba0e176a6f044f3082f9376e13a26f62",
        "IPY_MODEL_37e34f1a35d64d91bff35c00397fe46d",
        "IPY_MODEL_ca9418636a49457c9b2940f4a4db3a86"
       ],
       "layout": "IPY_MODEL_61d910b253034a97b5af881ec7986453"
      }
     },
     "78d65f761ed547d6837a46e7847fc411": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_395d939f88dd4f6cb6ecd59478551f38",
        "IPY_MODEL_52a9699aaee442a780b8355ecd02ac3e",
        "IPY_MODEL_5af3b34595994ba8affa88e0960a88a3"
       ],
       "layout": "IPY_MODEL_44b63cfdfd8e4dd7ac02e4f3883d69b2"
      }
     },
     "7ad6d29b9ef04f128efd27d88b27cf70": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7dde5f1705ea43e2904497f2d20096d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81c0c821b71e4c8ea4ca68cd41d18ffe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1f264b544f61441f98ced65713c80c37",
       "max": 481.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1b8915d9cdd44180a64144725dd2c288",
       "value": 481.0
      }
     },
     "850fb3798a5d49f38d040f80583c7e21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "87b2e5c1100f41f28eed7475e12673be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8863f814c5d74f01b8239111a46a4d9b",
       "placeholder": "",
       "style": "IPY_MODEL_1d80e55b41d4419c948c43dae22ef847",
       "value": " 481/481 [00:00&lt;00:00, 15.8kB/s]"
      }
     },
     "8863f814c5d74f01b8239111a46a4d9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8afbabe746014c61b584d0ac88074b3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "90312a6b09714938ae53a665a83dc151": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "919b24568f7942c5b20d8b2ab6bf3c23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9e0ea0adfbc247feb840c73c43648f78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7ad6d29b9ef04f128efd27d88b27cf70",
       "max": 1355863.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bc3c2b14e40f4ea8b2d5c3a25f7798f6",
       "value": 1355863.0
      }
     },
     "a9737b19871a480ea2e16060a765e8fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aaf133f790dd411b84c6d33e2e59e469": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ea5879ea35e04817b60aa1aba338973f",
       "placeholder": "",
       "style": "IPY_MODEL_b8fa9f540b8141828fcf1ed261cbeafa",
       "value": "Downloading: 100%"
      }
     },
     "ab0f35a216424784a26acd9b916b48db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8fa9f540b8141828fcf1ed261cbeafa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b913cebf1ecb4ff7bedcc8a53146b2d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba0e176a6f044f3082f9376e13a26f62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7dde5f1705ea43e2904497f2d20096d7",
       "placeholder": "",
       "style": "IPY_MODEL_919b24568f7942c5b20d8b2ab6bf3c23",
       "value": "Downloading: 100%"
      }
     },
     "bbd6b63de65b417d93c3f6da5033889a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc3c2b14e40f4ea8b2d5c3a25f7798f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ca9418636a49457c9b2940f4a4db3a86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bbd6b63de65b417d93c3f6da5033889a",
       "placeholder": "",
       "style": "IPY_MODEL_3a6565aa2933488d89f1c22345a46a34",
       "value": " 456k/456k [00:00&lt;00:00, 1.42MB/s]"
      }
     },
     "cb3f3bf79f49434ab9274d1d909e49cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5df179642d9645aeb840a9cd313b9593",
       "placeholder": "",
       "style": "IPY_MODEL_f4639d2a75294f7bbade3e912a3351da",
       "value": " 899k/899k [00:00&lt;00:00, 1.37MB/s]"
      }
     },
     "d46a7cdc22f14933a3abb33437491c89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d64fda070b884916b85ad57cfaabcb7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e2df47b82a44452ebb5867f0f189c796": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6fa03d85192487b8bcbc14fce2f6274": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ea5879ea35e04817b60aa1aba338973f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eecdc8c20e6f4262ae8ddd24cceb2229": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4639d2a75294f7bbade3e912a3351da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
